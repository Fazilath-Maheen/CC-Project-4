{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "48163d75-b12e-4062-8889-ee5c21d2aa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\fazil\\anaconda3\\lib\\site-packages (3.5.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\fazil\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "a3830631-1669-4c0f-b3e4-010106d016e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark Installed. Version: 3.5.3\n",
      "Spark session has successfully been created.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pyspark\n",
    "    from pyspark.sql import SparkSession\n",
    "    # Printing the PySpark version\n",
    "    print(f\"PySpark Installed. Version: {pyspark.__version__}\")\n",
    "    spark = SparkSession.builder.appName(\"TestInstallation\").getOrCreate()\n",
    "    print(\"Spark session has successfully been created.\")\n",
    "except ImportError:\n",
    "    print(\"PySpark is not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "a2663cdd-4b8a-4931-a6c1-1b6cabda963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "def load_data(year, location):\n",
    "    path = f\"C:/Users/fazil/Documents/WeatherData/{year}/{location}.csv\"\n",
    "    return spark.read.csv(path, header=True, inferSchema=True)\n",
    "# List of years and locations\n",
    "years = range(2015, 2025)\n",
    "locations = ['72429793812', '99495199999'] # Cincinnati and Florida\n",
    "# Create a dictionary to hold DataFrames\n",
    "dfs = {}\n",
    "for year in years:\n",
    "    for location in locations:\n",
    "        if year == 2016 and location == '99495199999':\n",
    "            continue\n",
    "        dfs[(year, location)] = load_data(year, location)\n",
    "print(len(dfs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "2910c614-7c18-42c6-8d34-e6076bbfd9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for 2015 72429793812: 365\n",
      "Row count for 2015 99495199999: 355\n",
      "Row count for 2016 72429793812: 366\n",
      "Row count for 2017 72429793812: 365\n",
      "Row count for 2017 99495199999: 283\n",
      "Row count for 2018 72429793812: 365\n",
      "Row count for 2018 99495199999: 363\n",
      "Row count for 2019 72429793812: 365\n",
      "Row count for 2019 99495199999: 345\n",
      "Row count for 2020 72429793812: 366\n",
      "Row count for 2020 99495199999: 365\n",
      "Row count for 2021 72429793812: 365\n",
      "Row count for 2021 99495199999: 104\n",
      "Row count for 2022 72429793812: 365\n",
      "Row count for 2022 99495199999: 259\n",
      "Row count for 2023 72429793812: 365\n",
      "Row count for 2023 99495199999: 276\n",
      "Row count for 2024 72429793812: 301\n",
      "Row count for 2024 99495199999: 133\n",
      "The number of results displayed are:19\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV files and display the count of each dataset:\n",
    "from pyspark.sql import SparkSession\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"WeatherAnalysis\").getOrCreate()\n",
    "# Define paths for the datasets\n",
    "#Years \n",
    "years = range(2015, 2025)\n",
    "#Station codes Cincinnati and Florida :\n",
    "locations = ['72429793812', '99495199999']\n",
    "datasets = {}\n",
    "# Load CSV files for each year and location\n",
    "for year in years:\n",
    "    for location in locations:\n",
    "        # if year == 2016 and location == '99495199999':\n",
    "        #     break\n",
    "        file_path = f\"C:/Users/fazil/Documents/WeatherData/{year}/{location}.csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            datasets[f\"{year}_{location}\"] = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "            print(f\"Row count for {year} {location}: {datasets[f'{year}_{location}'].count()}\")\n",
    "print(f'The number of results displayed are:{len(datasets)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "ea6470e9-205b-4ca3-95bb-a67ee67745f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Station, Name, Date and Maximum Teamparature of each year:\n",
      "   Station   |                 Station Name                       |    Date    | Maximum Temperature\n",
      "-------------|----------------------------------------------------|------------|---------------------\n",
      "72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 2015-06-12 |    91.9\n",
      "99495199999  | SEBASTIAN INLET STATE PARK, FL US                  | 2015-07-28 |    90.0\n",
      "-------------|----------------------------------------------------|------------|---------------------\n",
      "72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 2016-07-24 |    93.9\n",
      "-------------|----------------------------------------------------|------------|---------------------\n",
      "72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 2017-07-22 |    91.9\n",
      "99495199999  | SEBASTIAN INLET STATE PARK, FL US                  | 2017-02-22 |  9999.9\n",
      "-------------|----------------------------------------------------|------------|---------------------\n",
      "72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 2018-07-04 |    96.1\n",
      "99495199999  | SEBASTIAN INLET STATE PARK, FL US                  | 2018-09-15 |    90.1\n",
      "-------------|----------------------------------------------------|------------|---------------------\n",
      "72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 2019-09-30 |    95.0\n",
      "99495199999  | SEBASTIAN INLET STATE PARK, FL US                  | 2019-09-06 |    91.6\n",
      "-------------|----------------------------------------------------|------------|---------------------\n",
      "72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 2020-07-05 |    93.9\n",
      "99495199999  | SEBASTIAN INLET STATE PARK, FL US                  | 2020-04-13 |    91.8\n",
      "-------------|----------------------------------------------------|------------|---------------------\n",
      "72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 2021-08-12 |    95.0\n",
      "99495199999  | SEBASTIAN INLET STATE PARK, FL US                  | 2021-04-18 |    86.2\n",
      "-------------|----------------------------------------------------|------------|---------------------\n",
      "72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 2022-12-23 |  9999.9\n",
      "99495199999  | SEBASTIAN INLET STATE PARK, FL US                  | 2022-05-26 |  9999.9\n",
      "-------------|----------------------------------------------------|------------|---------------------\n",
      "72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 2023-08-23 |    96.1\n",
      "99495199999  | SEBASTIAN INLET STATE PARK, FL US                  | 2023-07-09 |    90.9\n",
      "-------------|----------------------------------------------------|------------|---------------------\n",
      "72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 2024-08-30 |   100.9\n",
      "99495199999  | SEBASTIAN INLET STATE PARK, FL US                  | 2024-05-14 |    86.7\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def hottest_day_each_year(dfs):\n",
    "    hottest_days = []\n",
    "    for (year, location), df in dfs.items():\n",
    "        # Check if the DataFrame is not empty\n",
    "        if not df.isEmpty():  # Ensure the DataFrame has data\n",
    "            hottest_day = df.orderBy(F.col(\"MAX\").desc()).first()\n",
    "            # Check if hottest_day is not None\n",
    "            if hottest_day is not None:  # Ensure we have a valid hottest day\n",
    "                hottest_days.append((year, hottest_day['STATION'], hottest_day['NAME'], hottest_day['DATE'], hottest_day['MAX']))\n",
    "    return hottest_days\n",
    "\n",
    "hottest_days_results = hottest_day_each_year(dfs)\n",
    "print(\"The Station, Name, Date and Maximum Teamparature of each year:\")\n",
    "print(f\"   Station   |                 Station Name                       |    Date    | Maximum Temperature\")\n",
    "for result in hottest_days_results:\n",
    "    # print(result)\n",
    "    if result[1]==72429793812:\n",
    "        print(f\"-------------|----------------------------------------------------|------------|---------------------\")\n",
    "    print(f\"{result[1]:^12} | {result[2]:<50} | {result[3]} | {result[4]:>7.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "805e8244-e273-4505-a50e-9fcad3a8d470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coldest Day in March is:\n",
      "   Station   |                 Station Name                       |    Date    | Minimum Temperature\n",
      "-------------|----------------------------------------------------|------------|---------------------\n",
      "72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 2015-03-06 | 3.2\n"
     ]
    }
   ],
   "source": [
    "def coldest_day_march(dfs):\n",
    "    coldest_day = None\n",
    "    for (year, location), df in dfs.items():\n",
    "        march_data = df.filter(F.month(\"DATE\") == 3)\n",
    "        if coldest_day is None or march_data.agg(F.min(\"MIN\")).first()[0] < coldest_day['MIN']:\n",
    "            coldest_day = march_data.orderBy(\"MIN\").first()\n",
    "    return (coldest_day['STATION'], coldest_day['NAME'], coldest_day['DATE'], coldest_day['MIN'])\n",
    "coldest_day_result = coldest_day_march(dfs)\n",
    "print(\"The coldest Day in March is:\")\n",
    "print(f\"   Station   |                 Station Name                       |    Date    | Minimum Temperature\")\n",
    "print(f\"-------------|----------------------------------------------------|------------|---------------------\")\n",
    "print(f\"{coldest_day_result[0]:^12} | {coldest_day_result[1]:<50} | {coldest_day_result[2]} | {coldest_day_result[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ba13535d-448a-460f-9933-5ce6fd8743a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year with Most Precipitation:\n",
      "---------------------------------------------------------------------------------------\n",
      "   Station   |                 Station Name                       | Year | Mean PRCP\n",
      "-------------|----------------------------------------------------|------|------------\n",
      "72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 2024 | 5.435647840531555\n",
      "99495199999  | SEBASTIAN INLET STATE PARK, FL US                  | 2015 | 0.0\n"
     ]
    }
   ],
   "source": [
    "def year_most_precipitation(dfs):\n",
    "    precipitation_results = {}\n",
    "    for (year, location), df in dfs.items():\n",
    "        year_mean_prcp = df.groupBy(F.year(\"DATE\")).agg(F.mean(\"PRCP\").alias(\"Mean_PRCP\"))\n",
    "        if location not in precipitation_results or year_mean_prcp.first()['Mean_PRCP'] > precipitation_results[location][1]:\n",
    "            precipitation_results[location] = (year,  year_mean_prcp.first()['Mean_PRCP'])\n",
    "    return precipitation_results\n",
    "most_precipitation_results = year_most_precipitation(dfs)\n",
    "print(\"Year with Most Precipitation:\")\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "print(f\"   Station   |                 Station Name                       | Year | Mean PRCP\")\n",
    "print(f\"-------------|----------------------------------------------------|------|------------\")\n",
    "for location, result in most_precipitation_results.items():\n",
    "    if location == '72429793812':\n",
    "        name = 'CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US'\n",
    "    else:\n",
    "        name = 'SEBASTIAN INLET STATE PARK, FL US'\n",
    "    print(f\"{location:^12} | {name:<50} | {result[0]} | {result[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "bc33c3f5-f34b-404a-adf2-e3aa83a6680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Wind Gust Percentages 2024 are:\n",
      " location  | Missing Gust Percentage\n",
      "-----------|-------------------------\n",
      "72429793812|  0.00%\n",
      "-----------|-------------------------\n",
      "99495199999|  0.00%\n"
     ]
    }
   ],
   "source": [
    "def missing_wind_gust_percentage(dfs):\n",
    "    missing_percentages = {}\n",
    "    for (year, location), df in dfs.items():\n",
    "        if year == 2024:\n",
    "            total = df.count()\n",
    "            missing = df.filter(df[\"GUST\"].isNull()).count()\n",
    "            percentage = (missing / total) * 100 if total > 0 else 0\n",
    "            missing_percentages[location] = percentage\n",
    "    return missing_percentages\n",
    "missing_gust_results = missing_wind_gust_percentage(dfs)\n",
    "print(\"Missing Wind Gust Percentages 2024 are:\")\n",
    "print(\" location  | Missing Gust Percentage\")\n",
    "for location, percentage in missing_gust_results.items():\n",
    "    print(\"-----------|-------------------------\")\n",
    "    print(f\"{location}|  {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "95cc3558-d4f8-4454-b51a-7c6d07c257e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Temperature Statistics(Mean, Standard Deviation, Median, Mode) for Cincinnati for Each Month in 2020:\n",
      "\n",
      "+-----+------------------+------------------+------+----+\n",
      "|MONTH|Mean              |StandardDeviation |Median|Mode|\n",
      "+-----+------------------+------------------+------+----+\n",
      "|1    |37.945161081129505|8.345810838316384 |37.7  |24.7|\n",
      "|2    |36.58965525133856 |7.901597947537755 |36.0  |25.9|\n",
      "|3    |49.0741934007214  |8.77940669347644  |47.8  |39.6|\n",
      "|4    |51.77999992370606 |7.3131621276074465|51.0  |49.4|\n",
      "|5    |60.89032290058751 |9.314768319579512 |63.7  |73.9|\n",
      "|6    |72.54666570027669 |4.8999458590264515|73.7  |70.7|\n",
      "|7    |77.6000001968876  |2.337947626620972 |77.9  |78.4|\n",
      "|8    |73.34516143798828 |3.4878690606063563|73.7  |78.3|\n",
      "|9    |66.09999961853028 |7.118261579669542 |65.8  |74.5|\n",
      "|10   |55.19354851015152 |6.7286914818367975|54.0  |52.2|\n",
      "|11   |48.00333340962728 |6.825938707865554 |47.7  |47.7|\n",
      "|12   |35.99354830095845 |6.6427872766495755|35.2  |32.1|\n",
      "+-----+------------------+------------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, month, mean, stddev, expr, count\n",
    "from pyspark.sql import Window\n",
    "\n",
    "# Define file path for Cincinnati 2020 data of the weather\n",
    "cin_2020_file = \"C:/Users/fazil/Documents/WeatherData/2020/72429793812.csv\"\n",
    "# Load 2020 data for Cincinnati, now!\n",
    "cin_2020_df = spark.read.option(\"header\", \"true\").csv(cin_2020_file)\n",
    "# Convert TEMP to float now\n",
    "cin_2020_df = cin_2020_df.withColumn(\"TEMP\", col(\"TEMP\").cast(\"float\"))\n",
    "# Filter out rows with missing or placeholder values for TEMP, e.g., 9999.9\n",
    "cin_2020_df = cin_2020_df.filter((col(\"TEMP\") != 9999.9) & (col(\"TEMP\").isNotNull()))\n",
    "# Group data by month and calculate mean and standard deviation, EACH MONTH of 2020\n",
    "temp_stats_df = cin_2020_df.withColumn(\"MONTH\", month(col(\"DATE\"))) \\\n",
    "    .groupBy(\"MONTH\") \\\n",
    "    .agg(\n",
    "        mean(\"TEMP\").alias(\"Mean \"),\n",
    "        stddev(\"TEMP\").alias(\"StandardDeviation\")\n",
    "    )\n",
    "# Calculate the median for each month of 2020\n",
    "temp_median_df = cin_2020_df.withColumn(\"MONTH\", month(col(\"DATE\"))) \\\n",
    "    .groupBy(\"MONTH\") \\\n",
    "    .agg(expr(\"percentile_approx(TEMP, 0.5)\").alias(\"Median\"))\n",
    "# Calculate the mode for each month of 2020\n",
    "window = Window.partitionBy(\"MONTH\")\n",
    "temp_mode_df = cin_2020_df.withColumn(\"MONTH\", month(col(\"DATE\"))) \\\n",
    "    .groupBy(\"MONTH\", \"TEMP\") \\\n",
    "    .agg(count(\"TEMP\").alias(\"Frequency\")) \\\n",
    "    .withColumn(\"Max_Freq\", expr(\"max(Frequency) over (PARTITION BY MONTH)\")) \\\n",
    "    .filter(col(\"Frequency\") == col(\"Max_Freq\")) \\\n",
    "    .groupBy(\"MONTH\") \\\n",
    "    .agg(expr(\"first(TEMP)\").alias(\"Mode\"))\n",
    "# Combine all statistics into a single DataFrame now\n",
    "final_stats_df = temp_stats_df \\\n",
    "    .join(temp_median_df, \"MONTH\") \\\n",
    "    .join(temp_mode_df, \"MONTH\") \\\n",
    "    .orderBy(\"MONTH\")\n",
    "# Display results in table format for the final answer\n",
    "print(\"\\nThe Temperature Statistics(Mean, Standard Deviation, Median, Mode) for Cincinnati for Each Month in 2020:\\n\")\n",
    "# Let's not truncate the values for better results (accurate)!\n",
    "final_stats_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "17507b91-9d78-4b85-bd02-8be3025efef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         STATION        DATE  LATITUDE  LONGITUDE  ELEVATION  \\\n",
      "6    72429793812  2017-01-07    39.106  -84.41609      144.8   \n",
      "364  72429793812  2017-12-31    39.106  -84.41609      144.8   \n",
      "360  72429793812  2017-12-27    39.106  -84.41609      144.8   \n",
      "361  72429793812  2017-12-28    39.106  -84.41609      144.8   \n",
      "5    72429793812  2017-01-06    39.106  -84.41609      144.8   \n",
      "7    72429793812  2017-01-08    39.106  -84.41609      144.8   \n",
      "358  72429793812  2017-12-25    39.106  -84.41609      144.8   \n",
      "363  72429793812  2017-12-30    39.106  -84.41609      144.8   \n",
      "4    72429793812  2017-01-05    39.106  -84.41609      144.8   \n",
      "359  72429793812  2017-12-26    39.106  -84.41609      144.8   \n",
      "\n",
      "                                                 NAME  TEMP  TEMP_ATTRIBUTES  \\\n",
      "6    CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US  10.5               24   \n",
      "364  CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US  11.0               24   \n",
      "360  CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US  13.0               24   \n",
      "361  CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US  13.6               24   \n",
      "5    CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US  13.6               24   \n",
      "7    CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US  15.9               24   \n",
      "358  CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US  25.8               24   \n",
      "363  CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US  21.6               24   \n",
      "4    CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US  22.2               24   \n",
      "359  CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US  23.3               24   \n",
      "\n",
      "     DEWP  DEWP_ATTRIBUTES  ...   GUST   MAX  MAX_ATTRIBUTES   MIN  \\\n",
      "6     0.4               24  ...  999.9  16.0                   6.1   \n",
      "364   2.3               24  ...  999.9  24.1                   6.1   \n",
      "360   1.1               24  ...  999.9  26.1                   5.0   \n",
      "361   2.3               24  ...  999.9  21.9                   5.0   \n",
      "5     4.9               24  ...   15.9  24.1                  10.0   \n",
      "7     5.8               24  ...  999.9  23.0                   6.1   \n",
      "358  14.8               24  ...   32.1  34.0               *  21.9   \n",
      "363  16.1               24  ...   20.0  28.9                  12.0   \n",
      "4    15.7               24  ...   15.9  25.0               *  19.9   \n",
      "359  10.4               24  ...  999.9  28.9                  19.9   \n",
      "\n",
      "     MIN_ATTRIBUTES  PRCP  PRCP_ATTRIBUTES   SNDP  FRSHTT  Wind_Chill  \n",
      "6                    0.00                G  999.9       0   -0.414016  \n",
      "364                  0.00                G  999.9    1000    2.033977  \n",
      "360                  0.00                G  999.9    1000    3.820646  \n",
      "361                  0.00                G  999.9       0    4.533355  \n",
      "5                    0.03                G  999.9       0    4.868933  \n",
      "7                    0.00                G  999.9    1000    7.929748  \n",
      "358               *  0.06                G  999.9    1000   14.285113  \n",
      "363                  0.07                G  999.9    1000   14.539211  \n",
      "4                 *  0.00                G  999.9    1000   14.748862  \n",
      "359                  0.00                G  999.9    1000   15.688978  \n",
      "\n",
      "[10 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Assuming you have a CSV file with columns 'DATE', 'TEMP', and 'WDSP'\n",
    "df = pd.read_csv('C:/Users/fazil/Documents/WeatherData/2017/72429793812.csv')\n",
    "# Filter data\n",
    "df = df[(df['TEMP'] < 50) & (df['WDSP'] > 3)]\n",
    "# Calculate Wind Chill\n",
    "df['Wind_Chill'] = 35.74 + 0.6215 * df['TEMP'] - 35.75 * df['WDSP']**0.16 + 0.4275 * df['TEMP'] * df['WDSP']**0.16\n",
    "# Sort by Wind Chill\n",
    "df_sorted = df.sort_values(by='Wind_Chill', ascending=True)\n",
    "# Display top 10 days\n",
    "df_sorted_top10 = df_sorted.head(10)\n",
    "print(df_sorted_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "40aa355b-2bb3-4469-9b30-02b9e109f708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extreme Weather Days for Florida: 0\n"
     ]
    }
   ],
   "source": [
    "def extreme_weather_days(dfs):\n",
    "    for (year, location), df in dfs.items():\n",
    "        if location == '99495199999':\n",
    "            extreme_conditions = df.filter(df['FRSHTT'] != 0).count()\n",
    "            return extreme_conditions\n",
    "    return 0\n",
    "extreme_weather_result = extreme_weather_days(dfs)\n",
    "print(\"Extreme Weather Days for Florida:\", extreme_weather_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "be823454-e3ce-4003-af79-5696fdfaf7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of days with extreme weather conditions in Florida from 2015-2024 is: 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"Extreme Weather Conditions for Florida\") \\\n",
    ".getOrCreate()\n",
    "# Path to the directory containing Florida weather data\n",
    "data_directory = \"C:/Users/fazil/Documents/WeatherData/\" # Update this with your actual path\n",
    "# Initialize an empty DataFrame\n",
    "florida_df = None\n",
    "# Load data for the years 2015 to 2024\n",
    "for year in range(2015, 2025):\n",
    "    try:\n",
    "        # Construct the file path for the Florida weather data\n",
    "        file_path = os.path.join(data_directory, str(year), \"99495199999.csv\") # Update with the correct station code\n",
    "        if (os.path.exists(file_path)):\n",
    "            yearly_data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "        # Union the current year's data with the overall DataFrame\n",
    "        if florida_df is None:\n",
    "            florida_df = yearly_data\n",
    "        else:\n",
    "            florida_df = florida_df.union(yearly_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for {year}: {e}\")\n",
    "# Check if the DataFrame is empty\n",
    "if florida_df is not None:\n",
    "    # Define extreme weather conditions: F = Fog, R = Rain, S = Snow\n",
    "    extreme_weather_conditions = ['F', 'R', 'S']\n",
    "    # Count distinct days with extreme weather conditions\n",
    "    extreme_weather_days_count = florida_df.filter(F.col(\"FRSHTT\") != 0) \\\n",
    "    .select(\"DATE\") \\\n",
    "    .distinct() \\\n",
    "    .count()\n",
    "    # Print the result\n",
    "    print(f\"The number of days with extreme weather conditions in Florida from 2015-2024 is: {extreme_weather_days_count}\")\n",
    "else:\n",
    "    print(\"data was not loaded for Florida.\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f6df5260-b104-437d-bdb1-59101e174b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for November and December 2024: [38.46783333]\n",
      "Mean Squared Error: 259.26903786657556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Load the data\n",
    "cincinnati_2022 = pd.read_csv('C:/Users/fazil/Documents/WeatherData/2015/72429793812.csv') # Adjust the path accordingly\n",
    "cincinnati_2023 = pd.read_csv('C:/Users/fazil/Documents/WeatherData/2016/72429793812.csv') # Adjust the path accordingly\n",
    "# Assuming the max temperature is under a different name, e.g., 'TMAX'\n",
    "# Prepare the data\n",
    "cincinnati_data = pd.concat([cincinnati_2022, cincinnati_2023])\n",
    "cincinnati_data['DATE'] = pd.to_datetime(cincinnati_data['DATE']) # Ensure DATE is in datetime format\n",
    "cincinnati_data['year'] = cincinnati_data['DATE'].dt.year\n",
    "cincinnati_data['month'] = cincinnati_data['DATE'].dt.month\n",
    "cincinnati_data['day'] = cincinnati_data['DATE'].dt.day\n",
    "# Replace 'TMAX' with the actual max temperature column name\n",
    "cincinnati_data = cincinnati_data[['year', 'month', 'day', 'TEMP']] # Use the correct column\n",
    "# Create lagged features\n",
    "for lag_year in range(1, 3):\n",
    "    lagged = cincinnati_data.copy()\n",
    "    lagged['year'] += lag_year\n",
    "    lagged.rename(columns={'TEMP': f'lag_max_temp_{lag_year}'}, inplace=True)\n",
    "    cincinnati_data = cincinnati_data.merge(lagged[['year', 'month', 'day', f'lag_max_temp_{lag_year}']],\n",
    "                                            on=['year', 'month', 'day'], how='left')\n",
    "# Prepare data for model training\n",
    "X = cincinnati_data[[f'lag_max_temp_{year}' for year in range(1, 3)]]\n",
    "y = cincinnati_data['TEMP'] # Use the actual max temp column\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Train the model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "# Predict for November and December 2024\n",
    "nov_dec_2024 = pd.DataFrame({'lag_max_temp_1': [X['lag_max_temp_1'].iloc[-1]],\n",
    "'lag_max_temp_2': [X['lag_max_temp_2'].iloc[-1]]})\n",
    "predictions = model.predict(nov_dec_2024)\n",
    "print(\"Predictions for November and December 2024:\", predictions)\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "27e00847-e295-436f-a66d-b0b8ccdd15ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cincinnati Data Count (Total Number of Rows): 3588\n",
      "----------------------------------------------------------------------\n",
      "Maximum Temperature for Cincinnati in November 2022                                     : 75.90°F\n",
      "Maximum Temperature for Cincinnati in November 2023                                     : 80.10°F\n",
      "The Predicted Maximum Temperature for Cincinnati in November 2024                       : 78.00°F\n",
      "\n",
      "Maximum Temperature for December 2022                                               : 66.00°F\n",
      "Cincinnati's Maximum Temperature for December 2023                                      : 64.00°F\n",
      "The Predicted Maximum Temperature for Cincinnati in December 2024                   : 65.00°F\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 10\n",
    "# Predict the maximum Temperature for Cincinnati for November and December 2024, based on the previous 2 years of weather data (Points: 1):\n",
    "# There should be 2 results.\n",
    "# You can use any model  to forecast on the historical weather data.\n",
    "\n",
    "# Here are the necessary imports\n",
    "from pyspark.sql.functions import col, avg, month, max, year\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, mean, stddev, count, when, expr, max as spark_max, min as spark_min, year, month\n",
    "\n",
    "# Let's create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Weather Data Analysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "cincinnati_files = [f\"C:/Users/fazil/Documents/WeatherData/{year}/72429793812.csv\" for year in years]\n",
    "cincinnati_df = spark.read.option(\"header\", \"true\").csv(cincinnati_files)\n",
    "# Display the total number of row counts\n",
    "print(f\"Cincinnati Data Count (Total Number of Rows): {cincinnati_df.count()}\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "# Filter the data for 2022 and 2023 values\n",
    "cincinnati_2022_2023 = cincinnati_df.filter((year(col(\"DATE\")).isin([2022, 2023])) & (col(\"MAX\") != 9999.9))\n",
    "\n",
    "# Calculating the max temperature for November in 2022 and 2023 in Cincinnati\n",
    "# 2022 Novemver max value\n",
    "nov_max_temp_2022 = cincinnati_2022_2023.filter((year(col(\"DATE\")) == 2022) & (month(col(\"DATE\")) == 11)) \\\n",
    "    .agg(max(\"MAX\").alias(\"Max_Nov_2022\")) \\\n",
    "    .collect()[0][\"Max_Nov_2022\"]\n",
    "\n",
    "# 2023 November max value\n",
    "nov_max_temp_2023 = cincinnati_2022_2023.filter((year(col(\"DATE\")) == 2023) & (month(col(\"DATE\")) == 11)) \\\n",
    "    .agg(max(\"MAX\").alias(\"Max_Nov_2023\")) \\\n",
    "    .collect()[0][\"Max_Nov_2023\"]\n",
    "\n",
    "# Now, 2022 DECEMBER\n",
    "dec_2022_all_temps = cincinnati_2022_2023.filter((year(col(\"DATE\")) == 2022) & (month(col(\"DATE\")) == 12)) \\\n",
    "    .orderBy(col(\"MAX\").desc())\n",
    "\n",
    "# Convert results to a list and get the highest values, ignoring the missing data which has a value of 9999.9\n",
    "dec_2022_max_values = [row[\"MAX\"] for row in dec_2022_all_temps.collect() if row[\"MAX\"] != 9999.9]\n",
    "\n",
    "if len(dec_2022_max_values) >= 2:\n",
    "    dec_max_temp_2022 = dec_2022_max_values[1]  # Highest Temperature Value\n",
    "elif len(dec_2022_max_values) == 1:\n",
    "    dec_max_temp_2022 = dec_2022_max_values[0]  # Only 1 Value\n",
    "else:\n",
    "    dec_max_temp_2022 = None  # No valid values found\n",
    "\n",
    "# Calculate the MAX temperature for December 2023\n",
    "dec_max_temp_2023 = cincinnati_2022_2023.filter((year(col(\"DATE\")) == 2023) & (month(col(\"DATE\")) == 12)) \\\n",
    "    .agg(max(\"MAX\").alias(\"Max_Dec_2023\")) \\\n",
    "    .collect()[0][\"Max_Dec_2023\"]\n",
    "\n",
    "# Calculating the averages of 2022 and 2023 for predicting the temperatures in November 2024 and December 2024\n",
    "nov_avg_max_temp = (float(nov_max_temp_2022) + float(nov_max_temp_2023)) / 2\n",
    "dec_avg_max_temp = (float(dec_max_temp_2022) + float(dec_max_temp_2023)) / 2 if dec_max_temp_2022 is not None else None\n",
    "\n",
    "#Printing the max temps for 2022 and 2023, and the predictions for 2024\n",
    "print(f\"Maximum Temperature for Cincinnati in November 2022                                     : {float(nov_max_temp_2022):.2f}°F\")\n",
    "print(f\"Maximum Temperature for Cincinnati in November 2023                                     : {float(nov_max_temp_2023):.2f}°F\")\n",
    "print(f\"The Predicted Maximum Temperature for Cincinnati in November 2024                       : {float(nov_avg_max_temp):.2f}°F\\n\")\n",
    "\n",
    "if dec_max_temp_2022 is not None:\n",
    "    print(f\"Maximum Temperature for December 2022                                               : {float(dec_max_temp_2022):.2f}°F\")\n",
    "else:\n",
    "    print(\"Maximum Temperature is not found for December 2022.\")\n",
    "print(f\"Cincinnati's Maximum Temperature for December 2023                                      : {float(dec_max_temp_2023):.2f}°F\")\n",
    "if dec_avg_max_temp is not None:\n",
    "    print(f\"The Predicted Maximum Temperature for Cincinnati in December 2024                   : {float(dec_avg_max_temp):.2f}°F\")\n",
    "else:\n",
    "    print(\"Missing Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9ac50f-ea6e-4f66-a790-f002a60f426b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
